"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.encodeURLtoURL = exports.encodeInBatches = exports.encodeText = exports.encodeSync = exports.encode = void 0;
const loader_utils_1 = require("@loaders.gl/loader-utils");
const worker_utils_1 = require("@loaders.gl/worker-utils");
const loader_utils_2 = require("@loaders.gl/loader-utils");
const loader_utils_3 = require("@loaders.gl/loader-utils");
const write_file_1 = require("../fetch/write-file");
const fetch_file_1 = require("../fetch/fetch-file");
const loader_options_1 = require("./loader-options");
/**
 * Encode loaded data into a binary ArrayBuffer using the specified Writer.
 */
async function encode(data, writer, options) {
    const globalOptions = (0, loader_options_1.getLoaderOptions)();
    // const globalOptions: WriterOptions = {}; // getWriterOptions();
    options = { ...globalOptions, ...options };
    if ((0, loader_utils_1.canEncodeWithWorker)(writer, options)) {
        return await (0, worker_utils_1.processOnWorker)(writer, data, options);
    }
    // TODO Merge default writer options with options argument like it is done in load module.
    if (writer.encode) {
        return await writer.encode(data, options);
    }
    if (writer.encodeSync) {
        return writer.encodeSync(data, options);
    }
    if (writer.encodeText) {
        return new TextEncoder().encode(await writer.encodeText(data, options));
    }
    if (writer.encodeInBatches) {
        // Create an iterator representing the data
        // TODO - Assumes this is a table
        const batches = encodeInBatches(data, writer, options);
        // Concatenate the output
        const chunks = [];
        for await (const batch of batches) {
            chunks.push(batch);
        }
        // @ts-ignore
        return (0, loader_utils_2.concatenateArrayBuffers)(...chunks);
    }
    if (!loader_utils_3.isBrowser && writer.encodeURLtoURL) {
        // TODO - how to generate filenames with correct extensions?
        const tmpInputFilename = getTemporaryFilename('input');
        await (0, write_file_1.writeFile)(tmpInputFilename, data);
        const tmpOutputFilename = getTemporaryFilename('output');
        const outputFilename = await encodeURLtoURL(tmpInputFilename, tmpOutputFilename, writer, options);
        const response = await (0, fetch_file_1.fetchFile)(outputFilename);
        return response.arrayBuffer();
    }
    throw new Error('Writer could not encode data');
}
exports.encode = encode;
/**
 * Encode loaded data into a binary ArrayBuffer using the specified Writer.
 */
function encodeSync(data, writer, options) {
    if (writer.encodeSync) {
        return writer.encodeSync(data, options);
    }
    throw new Error('Writer could not synchronously encode data');
}
exports.encodeSync = encodeSync;
/**
 * Encode loaded data to text using the specified Writer
 * @note This is a convenience function not intended for production use on large input data.
 * It is not optimized for performance. Data maybe converted from text to binary and back.
 * @throws if the writer does not generate text output
 */
async function encodeText(data, writer, options) {
    if (writer.text && writer.encodeText) {
        return await writer.encodeText(data, options);
    }
    if (writer.text && (writer.encode || writer.encodeInBatches)) {
        const arrayBuffer = await encode(data, writer, options);
        return new TextDecoder().decode(arrayBuffer);
    }
    throw new Error('Writer could not encode data as text');
}
exports.encodeText = encodeText;
/**
 * Encode loaded data into a sequence (iterator) of binary ArrayBuffers using the specified Writer.
 */
function encodeInBatches(data, writer, options) {
    if (writer.encodeInBatches) {
        const dataIterator = getIterator(data);
        return writer.encodeInBatches(dataIterator, options);
    }
    // TODO -fall back to atomic encode?
    throw new Error('Writer could not encode data in batches');
}
exports.encodeInBatches = encodeInBatches;
/**
 * Encode data stored in a file (on disk) to another file.
 * @note Node.js only. This function enables using command-line converters as "writers".
 */
async function encodeURLtoURL(inputUrl, outputUrl, writer, options) {
    inputUrl = (0, loader_utils_2.resolvePath)(inputUrl);
    outputUrl = (0, loader_utils_2.resolvePath)(outputUrl);
    if (loader_utils_3.isBrowser || !writer.encodeURLtoURL) {
        throw new Error();
    }
    const outputFilename = await writer.encodeURLtoURL(inputUrl, outputUrl, options);
    return outputFilename;
}
exports.encodeURLtoURL = encodeURLtoURL;
/**
 * @todo TODO - this is an unacceptable hack!!!
 */
function getIterator(data) {
    const dataIterator = [{ table: data, start: 0, end: data.length }];
    return dataIterator;
}
/**
 * @todo Move to utils
 */
function getTemporaryFilename(filename) {
    return `/tmp/${filename}`;
}
